---
title: Install the Kubernetes integration using Helm
contentType: page
template: basicDoc
topics:
  - Integrations
  - Kubernetes integration
  - Installation
japaneseVersion: ''
---

import { Link } from 'gatsby'

[Helm](https://helm.sh/) is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and manages dependencies for the services that you install in Kubernetes.

To install the integration using Helm, we recommend our Kubernetes automated installer, or you can complete the manual steps that follow.

<Button
  role="button"
  as={Link}
  to="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9"
  variant="primary"
>
  Start the installer
</Button>

<Callout variant="tip">
  To install the integration using manifests, see [Kubernetes integration: install and configure](/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration).
</Callout>

## Compatibility and requirements

Our Helm chart is compatible with both Helm 2 and 3. Make sure [Helm](https://github.com/helm/helm#install) is installed on your machine.

To install the Kubernetes integration using Helm you will need your New Relic account license key and your Kubernetes cluster's name:

1. Find and copy your [New Relic license key](/docs/accounts/install-new-relic/account-setup/license-key).
2. Find the name of your cluster with this command:

   ```
   kubectl config current-context
   ```
3. Make sure that `kube-state-metrics` is installed on your machine:

   ```
   kubectl get deployment --all-namespaces | grep kube-state-metrics
   ```

   If it's not installed, follow the [instructions in the kube-state-metrics GitHub repo](https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment) to install it.

## Install Kubernetes integration with Helm

Follow the instructions for your version of Helm:

<CollapserGroup>
  <Collapser
    className="freq-link"
    id="install-helm3"
    title="Helm 3"
  >
    To install using Helm 3:

    1. Set the cluster you want to install the agent in:

       ```
       kubectl config set-cluster DESIRED_CLUSTER
       ```

       <Callout variant="tip">
         To see the available clusters, run `kubectl config get-clusters`
       </Callout>
    2. Add the `New Relic Helm charts` repo:

       ```
       helm repo add newrelic https://helm-charts.newrelic.com
       ```
    3. Make sure everything is configured properly in the chart by running the following command (this step uses the `--dry-run` and `--debug` switches and therefore the agent is not installed):

       ```
       helm install newrelic/newrelic-infrastructure \
           --dry-run \
           --debug \
           --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \
           --set cluster=K8S_CLUSTER_NAME \
           --set config.custom_attributes.cluster=K8S_CLUSTER_NAME \
           --generate-name
       ```
    4. Install the Kubernetes integration:

       ```
       helm install newrelic/newrelic-infrastructure \
           --set licenseKey=yYOUR_NEW_RELIC_LICENSE_KEY \ 
           --set cluster=K8S_CLUSTER_NAME \ 
           --set config.custom_attributes.cluster=K8S_CLUSTER_NAME \
           --generate-name
       ```
    5. Ensure the `DaemonSet` and pods have been created:

       ```
       kubectl get daemonsets,pods
       ```

       <Callout variant="important">
         You may need to wait for a few seconds.
       </Callout>

    Make sure you see a `DaemonSet`, and one pod per node.
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-helm2"
    title="Helm 2"
  >
    To install using Helm 2:

    1. Set the cluster you want to install the agent in:

       ```
       kubectl config set-cluster DESIRED_CLUSTER
       ```

       <Callout variant="tip">
         To see the available clusters, run `kubectl config get-clusters`
       </Callout>
    2. If your cluster uses role-based access, create a service account for tiller (Helm's service which runs inside the Kubernetes cluster) using a Kubernetes manifest file:
       1. Paste the following in a manifest file `rbac-config.yaml`:

          ```
          apiVersion: v1 
          kind: ServiceAccount 
          metadata: 
            name: tiller 
            namespace: kube-system 
          --- 
          apiVersion: rbac.authorization.k8s.io/v1 
          kind: ClusterRoleBinding 
          metadata: 
            name: tiller 
          roleRef: 
            apiGroup: rbac.authorization.k8s.io 
            kind: ClusterRole 
            name: cluster-admin 
          subjects: 
            - kind: ServiceAccount 
              name: tiller 
              namespace: kube-system
          ```
       2. Create the service account and role by running:

          ```
          kubectl create -f rbac-config.yaml
          ```
    3. Initialize Helm so that Tiller is installed in the cluster:

       ```
       helm init --history-max 200
       ```
    4. Add the `New Relic Helm charts` repo:

       ```
       helm repo add newrelic https://helm-charts.newrelic.com
       ```
    5. Make sure everything is configured properly in the chart running the following command (this step uses the `--dry-run` and `--debug` switches and therefore the agent is not installed):

       ```
       helm install newrelic/newrelic-infrastructure \
           --dry-run \
           --debug \
           --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \
           --set cluster=K8S_CLUSTER_NAME \
           --set config.custom_attributes.cluster=K8S_CLUSTER_NAME
       ```
    6. Install the New Relic Kubernetes integration:

       <Callout variant="important">
         Note that the test switches have been removed.
       </Callout>

       ```
       helm install newrelic/newrelic-infrastructure \
           --set licenseKey=your_new_relic_license_key \
           --set cluster=K8S_CLUSTER_NAME \
           --set config.custom_attributes.cluster=K8S_CLUSTER_NAME
       ```
    7. Ensure the `DaemonSet` and pods have been created:

       ```
       kubectl get daemonsets,pods
       ```

       <Callout variant="important">
         You may need to wait for a few seconds.
       </Callout>

       Make sure you see a `DaemonSet`, and one pod per node.
  </Collapser>
</CollapserGroup>

## Helm configuration options

When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the `--set` flag.

```
helm install newrelic/newrelic-infrastructure \
    --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \
    --set cluster=YOUR_CLUSTER_NAME
```

<CollapserGroup>
  <Collapser
    id="config-parameters"
    title="Helm configuration parameters"
  >
    <Table>
      <thead>
        <tr>
          <th>
            Parameter
          </th>

          <th>
            Description
          </th>

          <th>
            Default
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `global.cluster` - `cluster`
          </td>

          <td>
            The cluster name for the Kubernetes cluster.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `global.licenseKey` - `licenseKey`
          </td>

          <td>
            The [license key](https://docs.newrelic.com/docs/accounts/install-new-relic/account-setup/license-key) for your New Relic Account. This will be the preferred configuration option if you're using both `licenseKey` and `customSecret`.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `global.customSecretName` - `customSecretName`
          </td>

          <td>
            The name of the Secret object where the license key is stored.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `global.customSecretLicenseKey` - `customSecretLicenseKey`
          </td>

          <td>
            The key in the Secret object where the license key is stored.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `config`
          </td>

          <td>
            A `newrelic.yml` file, if you're using one.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `enableLinux`
          </td>

          <td>
            Deploys the `DaemonSet` on all your Linux nodes.
          </td>

          <td>
            `true`
          </td>
        </tr>

        <tr>
          <td>
            `enableWindows`
          </td>

          <td>
            Deploys the `DaemonSet` on all your Windows nodes. For more information, see [Running on Windows](#running-on-windows)).
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `integrations_config`
          </td>

          <td>
            The list of integrations configured to monitor services running on Kubernetes. For more information, see [Monitor services running on Kubernetes](https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes).
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `disableKubeStateMetrics`
          </td>

          <td>
            Disables `kube-state-metrics` data parsing if the value is `true`.
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `kubeStateMetricsUrl`
          </td>

          <td>
            If provided, the discovery process for the `kube-state-metrics` endpoint won't be triggered. For example: `http://172.17.0.3:8080`
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `kubeStateMetricsPodLabel`
          </td>

          <td>
            If provided, we'll use this label to discover the `kube-state-metrics` pod. Set this to `true` on the target pod.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `kubeStateMetricsTimeout`
          </td>

          <td>
            The timeout for accessing `kube-state-metrics` in milliseconds. If it's not set, the default is `5000`.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `kubeStateMetricsScheme`
          </td>

          <td>
            If `kubeStateMetricsPodLabel` is present, it changes the scheme used to send a request to the pod.
          </td>

          <td>
            `http`
          </td>
        </tr>

        <tr>
          <td>
            `kubeStateMetricsPort`
          </td>

          <td>
            If `kubeStateMetricsPodLabel` is present, it changes the port queried in the pod.
          </td>

          <td>
            8080
          </td>
        </tr>

        <tr>
          <td>
            `rbac.create`
          </td>

          <td>
            Enable Role-based authentication.
          </td>

          <td>
            `true`
          </td>
        </tr>

        <tr>
          <td>
            `rbac.pspEnabled`
          </td>

          <td>
            Enable pod security policy support.
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `privileged`
          </td>

          <td>
            Enable privileged mode.
          </td>

          <td>
            `true`
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            The container to pull.
          </td>

          <td>
            `newrelic/infrastructure-k8s`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            The pull policy.
          </td>

          <td>
            `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullSecrets`
          </td>

          <td>
            The image pull secrets.
          </td>

          <td>
            `nil`
          </td>
        </tr>

        <tr>
          <td>
            `image.tag`
          </td>

          <td>
            The version of the container to pull.
          </td>

          <td>
            `1.26.5`
          </td>
        </tr>

        <tr>
          <td>
            `image.windowsTag`
          </td>

          <td>
            The version of the Windows container to pull.
          </td>

          <td>
            `1.21.0-windows-1809-alpha`
          </td>
        </tr>

        <tr>
          <td>
            `resources`
          </td>

          <td>
            Any resources you wish to assign to the pod.
          </td>

          <td>
            See [Resources](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-infrastructure#resources).
          </td>
        </tr>

        <tr>
          <td>
            `verboseLog`
          </td>

          <td>
            Should the agent use a verbose log? (Boolean)
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `priorityClassName`
          </td>

          <td>
            The scheduling priority of the pod.
          </td>

          <td>
            `nil`
          </td>
        </tr>

        <tr>
          <td>
            `nodeSelector`
          </td>

          <td>
            The node label to use for scheduling.
          </td>

          <td>
            `nil`
          </td>
        </tr>

        <tr>
          <td>
            `windowsNodeSelector`
          </td>

          <td>
            The Node label to use for scheduling on Windows nodes.
          </td>

          <td>
            `{ kubernetes.io/os: windows }`
          </td>
        </tr>

        <tr>
          <td>
            `tolerations`
          </td>

          <td>
            The list of node taints to tolerate (requires Kubernetes >= 1.6).
          </td>

          <td>
            See [Tolerations](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-infrastructure#tolerations).
          </td>
        </tr>

        <tr>
          <td>
            `updateStrategy`
          </td>

          <td>
            The strategy for DaemonSet updates (requires Kubernetes >= 1.6)
          </td>

          <td>
            `RollingUpdate`
          </td>
        </tr>

        <tr>
          <td>
            `serviveAccount.create`
          </td>

          <td>
            If true, a service account is created and assigned to the deployment.
          </td>

          <td>
            true
          </td>
        </tr>

        <tr>
          <td>
            `serviveAccount.name`
          </td>

          <td>
            The service account to assign to the deployment. If `serviveAccount.create` is true then this name will be used when creating the service account.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `serviveAccount.annotations`
          </td>

          <td>
            The annotations to add to the service account if `serviveAccount.create` is set to true.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `etcdTlsSecretName`
          </td>

          <td>
            The name of the secret containing the cacert, cert, and key used for setting the mTLS config for retrieving metrics from ETCD.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `etcdTlsSecretNamespace`
          </td>

          <td>
            The namespace where the secret specified in `etcdTlsSecretName` was created.
          </td>

          <td>
            `default`
          </td>
        </tr>

        <tr>
          <td>
            `etcdEndpointUrl`
          </td>

          <td>
            Explicitly sets the etcd component url.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `apiServerSecurePort`
          </td>

          <td>
            Set to query the API Server over a secure port.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `apiServerEndpointUrl`
          </td>

          <td>
            Explicitly sets the api server component url.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `schedulerEndpointUrl`
          </td>

          <td>
            Explicitly sets the scheduler component url.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `controllerManagerEndpointUrl`
          </td>

          <td>
            Explicitly sets the controller manager component url.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `eventQueueDepth`
          </td>

          <td>
            Increases the in-memory cache of the agent to accommodate for more samples at a time.
          </td>

          <td/>
        </tr>

        <tr>
          <td>
            `enableProcessMetrics`
          </td>

          <td>
            Enables the sending of process metrics to New Relic.
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `global.nrStaging` - `nrStaging`
          </td>

          <td>
            Send data to staging (requires a staging license key).
          </td>

          <td>
            `false`
          </td>
        </tr>

        <tr>
          <td>
            `discoveryCacheTTL`
          </td>

          <td>
            Duration since the discovered endpoints are stored in the cache until they expire. Valid time units: 'ns', 'us', 'ms', 's', 'm', 'h'
          </td>

          <td>
            `1h`
          </td>
        </tr>
      </tbody>
    </Table>
  </Collapser>
</CollapserGroup>

## Update via Helm

To update your Kubernetes integration installed via Helm, follow these steps:

1. Update the local chart repository

   ```
   helm repo update
   ```
2. Get the release name of the `newrelic-infrastructure` chart:

   ```
   helm list
   ```
3. Update the release:

   ```
   helm upgrade RELEASE_NAME newrelic/newrelic-infrastructure \ 
       --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \ 
       --set cluster=K8S_CLUSTER_NAME \         
       --set config.custom_attributes.cluster=K8S_CLUSTER_NAME
   ```
